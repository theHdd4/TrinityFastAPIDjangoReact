The Data Upload & Validate atom accepts CSV and Excel (`.xls`/`.xlsx`) files. On
upload each file is read with pandas using `parse_dates=True`. After loading the
service scans any string columns whose values resemble date patterns such as
`yyyy-mm-dd`, `dd-mm-yyyy` or `mm-dd-yyyy`. These columns are converted to
datetimes so the saved schema reports them with a `date` data type. Column names
are normalised by trimming whitespace, converting to lowercase and removing
inner spaces while keeping underscores. The resulting DataFrame is used to
derive a schema and is then stored as an Arrow file for the validator atom.

During validation the service checks that required columns are present and that
any configured range or periodicity rules pass. Range checks convert the
configured min/max values to the column's data type before comparison so numeric
and date ranges work correctly. If validation succeeds the
Arrow version of the file is uploaded to MinIO so other atoms can read it later.

When viewing a saved dataframe the CSV text is parsed client-side. Numeric
values are only converted when a cell consists entirely of digits. Date strings
remain unchanged so columns like `2025-07-14` or `07/14/2025` display exactly as
saved.

Advanced validations allow regex checks, null-percentage thresholds and
referential integrity lists. Regex patterns are evaluated against each row of the
selected column and must match the entire string. Null percentage checks fail if
the share of missing values exceeds the configured threshold. Referential
integrity ensures that column values appear in a predefined list. All validation
settings are stored with the project so they are reapplied whenever the master
file is used again.
