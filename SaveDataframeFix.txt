Action Plan for Consistent DataFrame Saving and Retrieval
========================================================

1. Centralize Path Construction
   - Create a single utility (e.g., build_data_path()) that derives the MinIO folder path from CLIENT_NAME, APP_NAME and PROJECT_NAME.
   - Replace all manual string concatenations in upload/validation and listing atoms with calls to this utility.

2. Validate & Sync Environment Variables
   - On application start and whenever a user enters a new project/app, reload CLIENT_NAME, APP_NAME and PROJECT_NAME from the active context.
   - Propagate these values through a shared store or event so every atom sees the latest project variables.
   - Expose configuration via a /config or /health endpoint to confirm values at runtime and reject actions if values mismatch the active project.

3. Align Cache & Persistence
   - Ensure the caching layer reads and writes using the same path generated by build_data_path().
   - Clear/invalidate cache entries when any of the three variables change.

4. Strengthen Logging & Monitoring
   - Add debug logs showing resolved MinIO paths for every save and list operation.
   - Send errors to a central log service so mismatches are visible.

5. Add Automated Tests
   - Unit tests: given different env var combinations, build_data_path() must produce the expected folder string.
   - Integration tests: upload and list endpoints should roundâ€‘trip a sample dataframe in an isolated bucket.

6. Document Workflow
   - Update developer docs to describe the required env vars and the standardized path format.
   - Include troubleshooting steps for mismatched paths or missing files.

Implementing the above will make file operations deterministic and easier to diagnose.
